{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598158d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Nets.ThermoNet.Development.ThermoNet import ThermoRegressionNet\n",
    "from Neural_Nets.ThermoDataset.Development.ThermoDataset import ThermoDataset\n",
    "from Neural_Nets.ThermoNetActFuncs.Development.ThermoNetActFuncs import Sigmoid, Softplus, ChenSundman, ELUFlipped, Log\n",
    "from Utils.PlotHandler.Development.PlotHandler import PlotHandler \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import Rprop, Adam\n",
    "from Data_Handling.SGTEHandler.Development.SGTEHandler import SGTEHandler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a1bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(net: ThermoRegressionNet, dataloader, loss_func, optimizer):\n",
    "    epoch_losses = np.zeros([len(dataloader), ])\n",
    "\n",
    "    for i, (temp, g, _, _, _) in enumerate(dataloader):\n",
    "        temp = temp.unsqueeze(-1)\n",
    "        \n",
    "        # Forward pass\n",
    "        gibbs_energy = net(temp)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_func(gibbs_energy, g.float())\n",
    "\n",
    "        # Backward pass\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses[i] = loss\n",
    "\n",
    "    print(gibbs_energy.min(), g.min())\n",
    "    mean_epoch_loss = epoch_losses.mean()\n",
    "    #print('Mean epoch loss: ', mean_epoch_loss)\n",
    "    return mean_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ada5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataset):\n",
    "    # Hyperparameters\n",
    "    n_epochs = 100\n",
    "    lr = 0.1\n",
    "    batch_size = 16\n",
    "    std_thresh = 0.05\n",
    "\n",
    "    # Data\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    # Keep track of epoch where learning rate was reduced last\n",
    "    lr_reduced_last = 0\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        #print('-----\\nEpoch %i:\\n' % i)\n",
    "        loss = epoch(net, dataloader, loss_func, optimizer)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Adapt learning rate if standard deviation over the last 10 epochs is below a threshold\n",
    "        if np.array(losses[-10:]).std() < std_thresh and (i - lr_reduced_last) >= 10:\n",
    "            print('Learning rate halfed! \\n')\n",
    "            lr_reduced_last = i\n",
    "            lr /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa160953",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fe successfully selected!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\5_Programmcodes\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\danie\\anaconda3\\envs\\5_Programmcodes\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.9289, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(0.7090, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.6568, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.3950, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8207, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.0733, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.6188, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0823, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9819, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.5717, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.4123, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.6716, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9012, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9065, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7468, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.6114, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.6436, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7831, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8818, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.8711, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7909, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7377, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7724, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8545, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8622, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8692, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8147, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7983, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8658, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9221, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8911, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8377, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8379, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8842, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9067, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8826, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8650, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8909, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9203, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9129, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8917, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8964, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9132, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9090, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8995, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9120, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9263, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9186, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9108, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9218, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9288, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9236, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9265, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9330, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9273, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9254, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9300, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8867, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9301, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9520, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9120, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9566, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9407, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9167, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9669, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9405, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9374, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9633, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9311, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9661, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9424, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9539, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9532, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8385, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0842, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9950, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9038, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8621, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8852, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-1.0866, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8291, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0441, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8543, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0662, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9100, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8873, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0157, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9222, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9924, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9010, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9747, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.9772, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8998, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0239, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8827, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.0977, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.7592, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-1.2060, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "tensor(-0.8036, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n",
      "Learning rate halfed! \n",
      "\n",
      "tensor(-0.9543, grad_fn=<MinBackward1>) tensor(-1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "net = ThermoRegressionNet(hidden_layers=1, hidden_dim=16, act_func=ELUFlipped())\n",
    "\n",
    "element = 'Fe'\n",
    "phase = ['BCC_A2']\n",
    "dataset = ThermoDataset(element, phase, step=100, scaling=True)\n",
    "\n",
    "train(net, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ae29a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fe successfully selected!\n",
      "\n",
      "tensor(1999., dtype=torch.float64)\n",
      "tensor([[ 322.3390],\n",
      "        [ 323.4339],\n",
      "        [ 324.5288],\n",
      "        ...,\n",
      "        [2181.4517],\n",
      "        [2182.5469],\n",
      "        [2183.6416]])\n",
      "tensor(125947.5078, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ph = PlotHandler()\n",
    "\n",
    "ph.properties_temp(net, element, phase, scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a159ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
