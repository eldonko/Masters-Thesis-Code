{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdb6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from binarypredictor.dataset import FunctionPairDataset\n",
    "from binarypredictor.net import DerivativeNet, TangentNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fd366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def epoch(net, train_loader, loss_func, optimizer, f_func, g_func):\n",
    "    \"\"\"\n",
    "    Training epoch of the network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    net : TangentNet \n",
    "        neural network to train\n",
    "    train_loader : DataLoader\n",
    "        training data\n",
    "    loss_func : torch.nn loss function\n",
    "        loss function\n",
    "    optimizer : torch.optim optimizer\n",
    "        optimizer\n",
    "    f_func : callable\n",
    "        function which is evaluated with the network outputs and compared to g_func\n",
    "    g_func : callable\n",
    "        function which is evaluated at x and compared to f_func\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float :\n",
    "        mean epoch loss\n",
    "    \"\"\"\n",
    "    \n",
    "    epoch_losses = np.zeros([len(train_loader), ])\n",
    "    \n",
    "    for i, d in enumerate(train_loader):\n",
    "        inp = torch.hstack((d[0][:, :, 0], d[0][:, :, 1]))  # network input\n",
    "        out = net(inp)  # network output\n",
    "        out = torch.clamp(out, min=1e-10, max=1.-1e-4)  # clamp outputs for numerical stability\n",
    "        \n",
    "        # Evaluate the functions for the loss (common tangent equations)\n",
    "        f = f_func(out, d[1][0])/d[2].unsqueeze(-1)\n",
    "        g = g_func(x, d[1][1])/d[2].unsqueeze(-1)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_func(f, g)\n",
    "        epoch_losses[i] = loss\n",
    "        \n",
    "        # Backward step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return epoch_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "32a6a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.enable_grad()\n",
    "def train(net, train_loader, test_loader, f_func, g_func, nr_epochs, lr, print_every=10, net_filename='net_1.pth'):\n",
    "    \"\"\"\n",
    "    Training of the network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    net : TangentNet \n",
    "        neural network to train\n",
    "    train_loader : DataLoader\n",
    "        training data\n",
    "    test_loader : DataLoader\n",
    "        test data\n",
    "    f_func : callable\n",
    "        function which is evaluated with the network outputs and compared to g_func\n",
    "    g_func : callable\n",
    "        function which is evaluated at x and compared to f_func\n",
    "    nr_epochs : int\n",
    "        number of epochs to train\n",
    "    lr : float\n",
    "        learning rate\n",
    "    print_every : int\n",
    "        multiple of epochs where losses are printed\n",
    "    net_filename : str\n",
    "        filename to save to net at\n",
    "        \n",
    "    Returns \n",
    "    -------\n",
    "    DerivativeNet :\n",
    "        net with best training loss\n",
    "    \"\"\"\n",
    "    \n",
    "    loss_func = nn.L1Loss()\n",
    "    optimizer = Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    losses = np.zeros([nr_epochs, ])\n",
    "    test_losses = np.zeros([nr_epochs // print_every, ])\n",
    "\n",
    "    best_loss = epoch(net, train_loader, loss_func, optimizer, f_func, g_func)\n",
    "    best_net = net\n",
    "    \n",
    "    for i in range(nr_epochs):\n",
    "        losses[i] = epoch(net, train_loader, loss_func, optimizer, f_func, g_func)\n",
    "        if losses[i] < best_loss:\n",
    "            best_net = net\n",
    "            best_loss = losses[i]\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print('Train loss : ', losses[i])\n",
    "            test_losses[i // print_every] = test(best_net, test_loader, f_func, g_func, loss_func)\n",
    "            print('Test loss: ', test_losses[i // print_every])\n",
    "            \n",
    "            torch.save(best_net, net_filename)\n",
    "    \n",
    "    return best_net, losses, test_losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(net, test_loader, f_func, g_func, metric): \n",
    "    \"\"\"\n",
    "    Training of the network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    net : TangentNet \n",
    "        neural network to test\n",
    "    test_loader : DataLoader\n",
    "        test data\n",
    "    f_func : callable\n",
    "        function which is evaluated with the network outputs and compared to g_func\n",
    "    g_func : callable\n",
    "        function which is evaluated at x and compared to f_func\n",
    "    metric : callable\n",
    "        metric to evaluate the network with\n",
    "        \n",
    "    Returns \n",
    "    -------\n",
    "    float :\n",
    "        loss on the test set\n",
    "    \"\"\"\n",
    "        \n",
    "    test_losses = np.zeros([len(train_loader), ])\n",
    "\n",
    "    for i, d in enumerate(test_loader):\n",
    "        inp = torch.hstack((d[0][:, :, 0], d[0][:, :, 1]))  # network input\n",
    "        out = net(inp)  # network output\n",
    "        \n",
    "        # Evaluate the functions for the loss (common tangent equations)\n",
    "        f = f_func(out, d[1][0])/d[2].unsqueeze(-1)\n",
    "        g = g_func(x, d[1][1])/d[2].unsqueeze(-1)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = metric(f, g)\n",
    "        test_losses[i] = loss\n",
    "    \n",
    "    return test_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a859ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(net_1, net_2, f, g, df, dg, scale=1., plot=False, acc=4, threshold=0.3, k=15):\n",
    "    \"\"\"\n",
    "    Predicts the equilibrium compositions of a binary system\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    net_1 : TangentNet\n",
    "        network to predict equation 1\n",
    "    net_2 : TangentNet \n",
    "        network to predict equation 2\n",
    "    f : callable\n",
    "        function for f\n",
    "    g : callable\n",
    "        function for g \n",
    "    df : torch.tensor\n",
    "        first derivative values of f at x\n",
    "    dg : torch.tensor\n",
    "        first derivative values of g at x\n",
    "    scale : float\n",
    "        scaling factor so that the maximum function value is 1\n",
    "    plot : bool\n",
    "        whether to plot the results\n",
    "    acc : int\n",
    "        accuracy of output values (number of decimals)\n",
    "    threshold : float\n",
    "        threshold for the deviation from the tangent's slope and the functions' slopes\n",
    "    k : int\n",
    "        select topk results that meet the tangent condition in order to speed up the algorithm\n",
    "    \"\"\"    \n",
    "    net_1.eval(), net_2.eval()\n",
    "    \n",
    "    # Network input\n",
    "    f_, g_ = f(x)/scale, g(x)/scale\n",
    "    inp = torch.hstack((f_, g_))\n",
    "    \n",
    "    # Network outputs\n",
    "    out_1 = net_1(inp)\n",
    "    out_2 = net_2(inp)\n",
    "                \n",
    "    # Get the equilibrium compositions by calculating the points of intersections (by approximating as the intersection\n",
    "    # of the lines connecting the values of out_1 and out_2 at sign changes)\n",
    "    out_diff = out_1 - out_2\n",
    "    idx = torch.where(abs(out_diff) < 0.1)[0][:-1]\n",
    "    \n",
    "    if len(idx) == 0:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "    \n",
    "    x_f = torch.hstack((out_1[idx], out_2[idx], out_1[idx + 1], out_2[idx + 1], \n",
    "                        (out_1[idx] + out_2[idx])/2, (out_1[idx + 1] + out_2[idx + 1])/2))\n",
    "    x_g = torch.hstack((x[idx], x[idx], x[idx + 1], x[idx + 1], x[idx], x[idx + 1]))\n",
    "    \n",
    "    # Get the function values at the equilibria\n",
    "    y_f, y_g = f(x_f)/scale, g(x_g)/scale\n",
    "            \n",
    "    # Get the slopes of the lines between the equilibria points\n",
    "    slopes = (y_g - y_f)/(x_g - x_f)\n",
    "        \n",
    "    # Remove lines that are not tangents\n",
    "    slope_cond = (abs(slopes - dg(x_g)/scale) <= threshold) & (abs(slopes - df(x_f)/scale) <= threshold)\n",
    "    idx = torch.where(slope_cond)[0]\n",
    "    \n",
    "    # Recalculate x and y values for all points that are tangent points\n",
    "    x_f, x_g = x_f[idx], x_g[idx]    \n",
    "    slope_dist = torch.sqrt((slopes[idx] - dg(x_g)/scale) ** 2 + (slopes[idx] - df(x_f)/scale) ** 2)\n",
    "    \n",
    "    # Only take the k best tangents to save time\n",
    "    idx = torch.topk(slope_dist, min(k, len(slope_dist)), largest=False)[1]\n",
    "    x_f, x_g = x_f[idx], x_g[idx]    \n",
    "    y_f, y_g = f(x_f)/scale, g(x_g)/scale\n",
    "    slope_dist = torch.sqrt((slopes[idx] - dg(x_g)/scale) ** 2 + (slopes[idx] - df(x_f)/scale) ** 2)\n",
    "    \n",
    "    # Choose the best tangent if there are multiple results for the same tangent\n",
    "    if len(x_f) > 0:\n",
    "        x_eqs = torch.tensor(list(zip(x_f, x_g)))\n",
    "        s_idx = torch.where(abs(torch.cdist(x_eqs, x_eqs)) < 0.05)\n",
    "        \n",
    "        left, right = s_idx[0], s_idx[1]\n",
    "        left_unique = torch.unique(left)\n",
    "        \n",
    "        cis = []\n",
    "        for i in left_unique:\n",
    "            idx = torch.where(left == i)[0]\n",
    "            add = right[idx]\n",
    "            if len(add) > 0:\n",
    "                cis.append(torch.argmin(slope_dist[add])) \n",
    "            else:\n",
    "                continue\n",
    "            right = torch.tensor([r for r in right if r not in add])\n",
    "            left = torch.tensor([l for l in left if l not in add]) \n",
    "            \n",
    "        cis = torch.tensor(cis)\n",
    "            \n",
    "        x_f, x_g = torch.unique(x_f[cis]), torch.unique(x_g[cis])\n",
    "        y_f, y_g = f(x_f)/scale, g(x_g)/scale\n",
    "    \n",
    "    # Plot the outputs\n",
    "    if plot:\n",
    "        plt.scatter(x, out_1.detach(), s=0.2)\n",
    "        plt.scatter(x, out_2.detach(), s=0.2)\n",
    "        plt.title('Network outputs')\n",
    "        plt.xlabel('x\\'\\'')\n",
    "        plt.ylabel('x\\'')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter(x, out_diff.detach(), s=0.2)\n",
    "        plt.title('Difference between network outputs')\n",
    "        plt.xlabel('x\\'\\'')\n",
    "        plt.ylabel('Difference')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        print('x\\'_eq: ', np.round(x_f.tolist(), decimals=acc))\n",
    "        print('x\\'\\'_eq: ', np.round(x_g.tolist(), decimals=acc))\n",
    "        \n",
    "        for x_f_eq, x_g_eq, y_f_eq, y_g_eq in zip(x_f, x_g, y_f, y_g):\n",
    "            plt.plot([x_f_eq, x_g_eq], [y_f_eq, y_g_eq], 'ro-')\n",
    "            plt.plot(x, f_)\n",
    "            plt.plot(x, g_)\n",
    "            plt.show()\n",
    "            \n",
    "    return x_f, x_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a295897",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 500\n",
    "in_features = out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e8f7fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpd = FunctionPairDataset(n_functions=250000, filename=\"train_1m.csv\", overwrite=True, step=1/in_features)\n",
    "fpd.create_functions()\n",
    "\n",
    "fpd_test = FunctionPairDataset(n_functions=1000, filename=\"test_1m.csv\", overwrite=True, step=1/in_features)\n",
    "fpd_test.create_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "ffe6fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(fpd, batch_size=1028)\n",
    "test_loader = DataLoader(fpd_test, batch_size=1028)\n",
    "net_1 = TangentNet(train=True, in_features=in_features * 2, out_features=out_features, hidden_size_linear=500, hidden_layers=2)\n",
    "net_2 = TangentNet(train=True, in_features=in_features * 2, out_features=out_features, hidden_size_linear=500, hidden_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "10e40015",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1e-10, 1., step=fpd_test.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nr_epochs = 250\n",
    "lr = 1e-3\n",
    "\n",
    "# Train for equation 1\n",
    "func_1 = lambda x_, d: fpd.first_derivative(**d, x=x_)\n",
    "best_net_1, losses_1, test_losses_1 = train(net_1, train_loader, test_loader, func_1, func_1, nr_epochs, lr, print_every=10, net_filename='net_1m.pth')\n",
    "\n",
    "print('Trained network 1 \\n')\n",
    "\n",
    "# Train for equation 2\n",
    "func_2 = lambda x_, d: fpd.base_function(**d, x=x_) - x_ * fpd.first_derivative(**d, x=x_)\n",
    "best_net_2, losses_2, test_losses_2 = train(net_2, train_loader, test_loader, func_2, func_2, nr_epochs, lr, print_every=10, net_filename='net_2m.pth')\n",
    "\n",
    "print('Trained network 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
